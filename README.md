# Edusign Model - American Sign Languange Translation

This project aims to translate American Sign Language (ASL) videos into text using landmark detection and machine learning models in Python and TensorFlow. The project involves extracting frames from the video, applying landmark detection to these frames, and predicting the sign language based on the processed video frames.

# Dataset
We are using two datasets: one is the original dataset, and the other is a resized version. We are taking this approach because some videos from the original dataset are corrupted and need to be replaced with videos from the resized dataset. The combined dataset contains 21,083 videos and 2,000 glossarium labels.

- **Original Dataset**: https://www.kaggle.com/datasets/risangbaskoro/wlasl-processed
- **Resized Dataset**: https://www.kaggle.com/datasets/sttaseen/wlasl2000-resized

# Research Method

# Model Architecture

# Requirements
- Python
- Pandas
- Numpy
- Sklearn (scikit-learn)
- MediaPipe
- TensorFlow
- OpenCV
- Matplotlib
- Seaborn
- Tqdm

# Usage

# References

# Authors

This project is developed by C241-PS015 Team Bangkit as part of Bangkit Product Capstone.
1. M006D4KY2955 – Yehezkiel Stephanus Austin
2. M006D4KY2954 – Juan Christopher Young
3. M006D4KY2953 – Haikal Irfano
