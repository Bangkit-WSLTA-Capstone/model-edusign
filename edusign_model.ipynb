{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":46105,"databundleVersionId":5087314,"sourceType":"competition"},{"sourceId":5315518,"sourceType":"datasetVersion","datasetId":3036481}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# input_data data files are available in the read-only \"../input_data/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input_data directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input_data'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-06-02T09:37:02.819525Z","iopub.execute_input":"2024-06-02T09:37:02.820113Z","iopub.status.idle":"2024-06-02T09:37:03.183806Z","shell.execute_reply.started":"2024-06-02T09:37:02.820077Z","shell.execute_reply":"2024-06-02T09:37:03.182835Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n# import tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sn\n\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split, GroupShuffleSplit \n\nimport glob\nimport sys\nimport os\nimport math\nimport gc\nimport sys\nimport sklearn\nimport scipy","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:03.185712Z","iopub.execute_input":"2024-06-02T09:37:03.186238Z","iopub.status.idle":"2024-06-02T09:37:06.853261Z","shell.execute_reply.started":"2024-06-02T09:37:03.186205Z","shell.execute_reply":"2024-06-02T09:37:06.852420Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-02 09:37:03.543997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-02 09:37:03.544045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-02 09:37:03.545750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EduSign","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/asl-signs/train.csv')\nlen(train)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:06.854326Z","iopub.execute_input":"2024-06-02T09:37:06.854813Z","iopub.status.idle":"2024-06-02T09:37:06.991357Z","shell.execute_reply.started":"2024-06-02T09:37:06.854785Z","shell.execute_reply":"2024-06-02T09:37:06.990439Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"94477"},"metadata":{}}]},{"cell_type":"code","source":"display(train.head(5))\ndisplay(train.info())","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:06.993893Z","iopub.execute_input":"2024-06-02T09:37:06.994258Z","iopub.status.idle":"2024-06-02T09:37:07.035837Z","shell.execute_reply.started":"2024-06-02T09:37:06.994226Z","shell.execute_reply":"2024-06-02T09:37:07.034806Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                            path  participant_id  sequence_id  \\\n0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n\n    sign  \n0   blow  \n1   wait  \n2  cloud  \n3   bird  \n4   owie  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>participant_id</th>\n      <th>sequence_id</th>\n      <th>sign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmark_files/26734/1000035562.parquet</td>\n      <td>26734</td>\n      <td>1000035562</td>\n      <td>blow</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmark_files/28656/1000106739.parquet</td>\n      <td>28656</td>\n      <td>1000106739</td>\n      <td>wait</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmark_files/16069/100015657.parquet</td>\n      <td>16069</td>\n      <td>100015657</td>\n      <td>cloud</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmark_files/25571/1000210073.parquet</td>\n      <td>25571</td>\n      <td>1000210073</td>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmark_files/62590/1000240708.parquet</td>\n      <td>62590</td>\n      <td>1000240708</td>\n      <td>owie</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 94477 entries, 0 to 94476\nData columns (total 4 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   path            94477 non-null  object\n 1   participant_id  94477 non-null  int64 \n 2   sequence_id     94477 non-null  int64 \n 3   sign            94477 non-null  object\ndtypes: int64(2), object(2)\nmemory usage: 2.9+ MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"markdown","source":"# CONFIG","metadata":{}},{"cell_type":"code","source":"TOTAL_LANDMARKS = 543 #33 Pose, 468 Face , 21 Hand\nNUM_CLASS = 250\nVERBOSE = 2\nPAD = -100\nN_DIMS = 2\nN_SAMPLES = len(train)\nSEED = 102\n\n# LANDMARK (BECAUSE THE DATASET USING OLD MEDIAPIPE, THERE WILL BE RIGHT HAND AND LEFT HAND)\nUSED_LANDMARK = ['left_hand', 'pose', 'right_hand']\nSTART_INDICES = 468\nLIPS_INDICES = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n        95, 88, 178, 87, 14, 317, 402, 318, 324, 308, ]\n\nLEFT_HAND_INDICES = np.arange(468,489)\nRIGHT_HAND_INDICES = np.arange(522,543)\nLEFT_POSE_INDICES = np.array([502, 504, 506, 508, 510])\nRIGHT_POSE_INDICES = np.array([503, 505, 507, 509, 511])\nINDICES_LEFT_DOMINANT = np.concatenate((LIPS_INDICES, LEFT_HAND_INDICES, LEFT_POSE_INDICES))\nINDICES_RIGHT_DOMINANT  = np.concatenate((LIPS_INDICES, RIGHT_HAND_INDICES, RIGHT_POSE_INDICES))\nHANDS_LANDMARK = np.concatenate((LEFT_HAND_INDICES, RIGHT_HAND_INDICES), axis = 0)\nN_COLS = INDICES_LEFT_DOMINANT.size\n\nLIPS_IDXS = np.argwhere(np.isin(INDICES_LEFT_DOMINANT, LIPS_INDICES)).squeeze()\nLEFT_HAND_IDXS = np.argwhere(np.isin(INDICES_LEFT_DOMINANT, LEFT_HAND_INDICES)).squeeze()\nRIGHT_HAND_IDXS = np.argwhere(np.isin(INDICES_LEFT_DOMINANT, RIGHT_HAND_INDICES)).squeeze()\nHAND_IDXS = np.argwhere(np.isin(INDICES_LEFT_DOMINANT, HANDS_LANDMARK)).squeeze()\nPOSE_IDXS = np.argwhere(np.isin(INDICES_LEFT_DOMINANT, LEFT_POSE_INDICES)).squeeze()\n\n#FOR TRAINING\nBATCH_ALL_SIGNS_N = 4\nINPUT_SIZE = 64 #How Many Frame\nBACTCH_SIZE = 256\nN_EPOCHS = 1000\nLR = 1e-4\nMASK_VAL = 4237","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:07.036984Z","iopub.execute_input":"2024-06-02T09:37:07.037253Z","iopub.status.idle":"2024-06-02T09:37:07.050628Z","shell.execute_reply.started":"2024-06-02T09:37:07.037228Z","shell.execute_reply":"2024-06-02T09:37:07.049760Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_file_path(path):\n    return f'/kaggle/input/asl-signs/{path}'\n\ntrain['file_path'] = train['path'].apply(get_file_path)\ndisplay(train.head(5))","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:07.051927Z","iopub.execute_input":"2024-06-02T09:37:07.052305Z","iopub.status.idle":"2024-06-02T09:37:07.107403Z","shell.execute_reply.started":"2024-06-02T09:37:07.052270Z","shell.execute_reply":"2024-06-02T09:37:07.106535Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                            path  participant_id  sequence_id  \\\n0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n\n    sign                                          file_path  \n0   blow  /kaggle/input/asl-signs/train_landmark_files/2...  \n1   wait  /kaggle/input/asl-signs/train_landmark_files/2...  \n2  cloud  /kaggle/input/asl-signs/train_landmark_files/1...  \n3   bird  /kaggle/input/asl-signs/train_landmark_files/2...  \n4   owie  /kaggle/input/asl-signs/train_landmark_files/6...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>participant_id</th>\n      <th>sequence_id</th>\n      <th>sign</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmark_files/26734/1000035562.parquet</td>\n      <td>26734</td>\n      <td>1000035562</td>\n      <td>blow</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmark_files/28656/1000106739.parquet</td>\n      <td>28656</td>\n      <td>1000106739</td>\n      <td>wait</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmark_files/16069/100015657.parquet</td>\n      <td>16069</td>\n      <td>100015657</td>\n      <td>cloud</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmark_files/25571/1000210073.parquet</td>\n      <td>25571</td>\n      <td>1000210073</td>\n      <td>bird</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmark_files/62590/1000240708.parquet</td>\n      <td>62590</td>\n      <td>1000240708</td>\n      <td>owie</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/6...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Encode the label","metadata":{}},{"cell_type":"code","source":"train['ord_value'] = train['sign'].astype('category').cat.codes\ndisplay(train)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:07.108542Z","iopub.execute_input":"2024-06-02T09:37:07.108892Z","iopub.status.idle":"2024-06-02T09:37:07.132581Z","shell.execute_reply.started":"2024-06-02T09:37:07.108843Z","shell.execute_reply":"2024-06-02T09:37:07.131699Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                path  participant_id  \\\n0      train_landmark_files/26734/1000035562.parquet           26734   \n1      train_landmark_files/28656/1000106739.parquet           28656   \n2       train_landmark_files/16069/100015657.parquet           16069   \n3      train_landmark_files/25571/1000210073.parquet           25571   \n4      train_landmark_files/62590/1000240708.parquet           62590   \n...                                              ...             ...   \n94472   train_landmark_files/53618/999786174.parquet           53618   \n94473   train_landmark_files/26734/999799849.parquet           26734   \n94474   train_landmark_files/25571/999833418.parquet           25571   \n94475   train_landmark_files/29302/999895257.parquet           29302   \n94476   train_landmark_files/36257/999962374.parquet           36257   \n\n       sequence_id    sign                                          file_path  \\\n0       1000035562    blow  /kaggle/input/asl-signs/train_landmark_files/2...   \n1       1000106739    wait  /kaggle/input/asl-signs/train_landmark_files/2...   \n2        100015657   cloud  /kaggle/input/asl-signs/train_landmark_files/1...   \n3       1000210073    bird  /kaggle/input/asl-signs/train_landmark_files/2...   \n4       1000240708    owie  /kaggle/input/asl-signs/train_landmark_files/6...   \n...            ...     ...                                                ...   \n94472    999786174   white  /kaggle/input/asl-signs/train_landmark_files/5...   \n94473    999799849    have  /kaggle/input/asl-signs/train_landmark_files/2...   \n94474    999833418  flower  /kaggle/input/asl-signs/train_landmark_files/2...   \n94475    999895257    room  /kaggle/input/asl-signs/train_landmark_files/2...   \n94476    999962374   happy  /kaggle/input/asl-signs/train_landmark_files/3...   \n\n       ord_value  \n0             25  \n1            232  \n2             48  \n3             23  \n4            164  \n...          ...  \n94472        238  \n94473        108  \n94474         86  \n94475        188  \n94476        105  \n\n[94477 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>participant_id</th>\n      <th>sequence_id</th>\n      <th>sign</th>\n      <th>file_path</th>\n      <th>ord_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmark_files/26734/1000035562.parquet</td>\n      <td>26734</td>\n      <td>1000035562</td>\n      <td>blow</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmark_files/28656/1000106739.parquet</td>\n      <td>28656</td>\n      <td>1000106739</td>\n      <td>wait</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmark_files/16069/100015657.parquet</td>\n      <td>16069</td>\n      <td>100015657</td>\n      <td>cloud</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/1...</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmark_files/25571/1000210073.parquet</td>\n      <td>25571</td>\n      <td>1000210073</td>\n      <td>bird</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmark_files/62590/1000240708.parquet</td>\n      <td>62590</td>\n      <td>1000240708</td>\n      <td>owie</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/6...</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94472</th>\n      <td>train_landmark_files/53618/999786174.parquet</td>\n      <td>53618</td>\n      <td>999786174</td>\n      <td>white</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/5...</td>\n      <td>238</td>\n    </tr>\n    <tr>\n      <th>94473</th>\n      <td>train_landmark_files/26734/999799849.parquet</td>\n      <td>26734</td>\n      <td>999799849</td>\n      <td>have</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>94474</th>\n      <td>train_landmark_files/25571/999833418.parquet</td>\n      <td>25571</td>\n      <td>999833418</td>\n      <td>flower</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>94475</th>\n      <td>train_landmark_files/29302/999895257.parquet</td>\n      <td>29302</td>\n      <td>999895257</td>\n      <td>room</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/2...</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>94476</th>\n      <td>train_landmark_files/36257/999962374.parquet</td>\n      <td>36257</td>\n      <td>999962374</td>\n      <td>happy</td>\n      <td>/kaggle/input/asl-signs/train_landmark_files/3...</td>\n      <td>105</td>\n    </tr>\n  </tbody>\n</table>\n<p>94477 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Dictionaries to translate sign <-> ordinal encoded sign\nSIGN2ORD = train[['sign', 'ord_value']].set_index('sign').squeeze().to_dict()\nORD2SIGN = train[['ord_value', 'sign']].set_index('ord_value').squeeze().to_dict()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:37:07.133572Z","iopub.execute_input":"2024-06-02T09:37:07.133824Z","iopub.status.idle":"2024-06-02T09:37:07.286785Z","shell.execute_reply.started":"2024-06-02T09:37:07.133802Z","shell.execute_reply":"2024-06-02T09:37:07.286075Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"SIGN2ORD","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-02T09:37:07.287928Z","iopub.execute_input":"2024-06-02T09:37:07.288261Z","iopub.status.idle":"2024-06-02T09:37:07.302661Z","shell.execute_reply.started":"2024-06-02T09:37:07.288230Z","shell.execute_reply":"2024-06-02T09:37:07.301764Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'blow': 25,\n 'wait': 232,\n 'cloud': 48,\n 'bird': 23,\n 'owie': 164,\n 'duck': 67,\n 'minemy': 143,\n 'lips': 134,\n 'flower': 86,\n 'time': 220,\n 'vacuum': 231,\n 'apple': 8,\n 'puzzle': 180,\n 'mitten': 144,\n 'there': 216,\n 'dry': 65,\n 'shirt': 195,\n 'owl': 165,\n 'yellow': 243,\n 'not': 156,\n 'zipper': 249,\n 'clean': 45,\n 'closet': 47,\n 'quiet': 181,\n 'have': 108,\n 'brother': 30,\n 'clown': 49,\n 'cheek': 41,\n 'cute': 54,\n 'store': 207,\n 'shoe': 196,\n 'wet': 235,\n 'see': 193,\n 'empty': 70,\n 'fall': 74,\n 'balloon': 14,\n 'frenchfries': 89,\n 'finger': 80,\n 'same': 190,\n 'cry': 52,\n 'hungry': 121,\n 'orange': 162,\n 'milk': 142,\n 'go': 97,\n 'drawer': 62,\n 'TV': 0,\n 'another': 6,\n 'giraffe': 93,\n 'wake': 233,\n 'bee': 19,\n 'bad': 13,\n 'can': 35,\n 'say': 191,\n 'callonphone': 34,\n 'finish': 81,\n 'old': 159,\n 'backyard': 12,\n 'sick': 198,\n 'look': 136,\n 'that': 215,\n 'black': 24,\n 'yourself': 246,\n 'open': 161,\n 'alligator': 4,\n 'moon': 146,\n 'find': 78,\n 'pizza': 172,\n 'shhh': 194,\n 'fast': 76,\n 'jacket': 125,\n 'scissors': 192,\n 'now': 157,\n 'man': 140,\n 'sticky': 206,\n 'jump': 127,\n 'sleep': 199,\n 'sun': 210,\n 'first': 83,\n 'grass': 101,\n 'uncle': 228,\n 'fish': 84,\n 'cowboy': 51,\n 'snow': 203,\n 'dryer': 66,\n 'green': 102,\n 'bug': 32,\n 'nap': 150,\n 'feet': 77,\n 'yucky': 247,\n 'morning': 147,\n 'sad': 189,\n 'face': 73,\n 'penny': 169,\n 'gift': 92,\n 'night': 152,\n 'hair': 104,\n 'who': 239,\n 'think': 217,\n 'brown': 31,\n 'mad': 138,\n 'bed': 17,\n 'drink': 63,\n 'stay': 205,\n 'flag': 85,\n 'tooth': 223,\n 'awake': 11,\n 'thankyou': 214,\n 'hot': 120,\n 'like': 132,\n 'where': 237,\n 'hesheit': 115,\n 'potty': 176,\n 'down': 61,\n 'stuck': 209,\n 'no': 153,\n 'head': 110,\n 'food': 87,\n 'pretty': 178,\n 'nuts': 158,\n 'animal': 5,\n 'frog': 90,\n 'beside': 21,\n 'noisy': 154,\n 'water': 234,\n 'weus': 236,\n 'happy': 105,\n 'white': 238,\n 'bye': 33,\n 'high': 117,\n 'fine': 79,\n 'boat': 27,\n 'all': 3,\n 'tiger': 219,\n 'pencil': 168,\n 'sleepy': 200,\n 'grandma': 99,\n 'chocolate': 44,\n 'haveto': 109,\n 'radio': 182,\n 'farm': 75,\n 'any': 7,\n 'zebra': 248,\n 'rain': 183,\n 'toy': 226,\n 'donkey': 60,\n 'lion': 133,\n 'drop': 64,\n 'many': 141,\n 'bath': 15,\n 'aunt': 10,\n 'will': 241,\n 'hate': 107,\n 'on': 160,\n 'pretend': 177,\n 'kitty': 129,\n 'fireman': 82,\n 'before': 20,\n 'doll': 59,\n 'stairs': 204,\n 'kiss': 128,\n 'loud': 137,\n 'hen': 114,\n 'listen': 135,\n 'give': 95,\n 'wolf': 242,\n 'dad': 55,\n 'gum': 103,\n 'hear': 111,\n 'refrigerator': 186,\n 'outside': 163,\n 'cut': 53,\n 'underwear': 229,\n 'please': 173,\n 'child': 42,\n 'smile': 201,\n 'pen': 167,\n 'yesterday': 245,\n 'horse': 119,\n 'pig': 171,\n 'table': 211,\n 'eye': 72,\n 'snack': 202,\n 'story': 208,\n 'police': 174,\n 'arm': 9,\n 'talk': 212,\n 'grandpa': 100,\n 'tongue': 222,\n 'pool': 175,\n 'girl': 94,\n 'up': 230,\n 'better': 22,\n 'tree': 227,\n 'dance': 56,\n 'close': 46,\n 'taste': 213,\n 'chin': 43,\n 'ride': 187,\n 'because': 16,\n 'if': 123,\n 'cat': 38,\n 'why': 240,\n 'carrot': 37,\n 'dog': 58,\n 'mouse': 148,\n 'jeans': 126,\n 'shower': 197,\n 'later': 131,\n 'mom': 145,\n 'nose': 155,\n 'yes': 244,\n 'airplane': 2,\n 'book': 28,\n 'blue': 26,\n 'icecream': 122,\n 'garbage': 91,\n 'tomorrow': 221,\n 'red': 185,\n 'cow': 50,\n 'person': 170,\n 'puppy': 179,\n 'cereal': 39,\n 'touch': 225,\n 'mouth': 149,\n 'boy': 29,\n 'thirsty': 218,\n 'make': 139,\n 'for': 88,\n 'glasswindow': 96,\n 'into': 124,\n 'read': 184,\n 'every': 71,\n 'bedroom': 18,\n 'napkin': 151,\n 'ear': 68,\n 'toothbrush': 224,\n 'home': 118,\n 'pajamas': 166,\n 'hello': 113,\n 'helicopter': 112,\n 'lamp': 130,\n 'room': 188,\n 'dirty': 57,\n 'chair': 40,\n 'hat': 106,\n 'elephant': 69,\n 'after': 1,\n 'car': 36,\n 'hide': 116,\n 'goose': 98}"},"metadata":{}}]},{"cell_type":"code","source":"ORD2SIGN","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-02T09:37:07.305202Z","iopub.execute_input":"2024-06-02T09:37:07.305498Z","iopub.status.idle":"2024-06-02T09:37:07.320857Z","shell.execute_reply.started":"2024-06-02T09:37:07.305466Z","shell.execute_reply":"2024-06-02T09:37:07.319947Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{25: 'blow',\n 232: 'wait',\n 48: 'cloud',\n 23: 'bird',\n 164: 'owie',\n 67: 'duck',\n 143: 'minemy',\n 134: 'lips',\n 86: 'flower',\n 220: 'time',\n 231: 'vacuum',\n 8: 'apple',\n 180: 'puzzle',\n 144: 'mitten',\n 216: 'there',\n 65: 'dry',\n 195: 'shirt',\n 165: 'owl',\n 243: 'yellow',\n 156: 'not',\n 249: 'zipper',\n 45: 'clean',\n 47: 'closet',\n 181: 'quiet',\n 108: 'have',\n 30: 'brother',\n 49: 'clown',\n 41: 'cheek',\n 54: 'cute',\n 207: 'store',\n 196: 'shoe',\n 235: 'wet',\n 193: 'see',\n 70: 'empty',\n 74: 'fall',\n 14: 'balloon',\n 89: 'frenchfries',\n 80: 'finger',\n 190: 'same',\n 52: 'cry',\n 121: 'hungry',\n 162: 'orange',\n 142: 'milk',\n 97: 'go',\n 62: 'drawer',\n 0: 'TV',\n 6: 'another',\n 93: 'giraffe',\n 233: 'wake',\n 19: 'bee',\n 13: 'bad',\n 35: 'can',\n 191: 'say',\n 34: 'callonphone',\n 81: 'finish',\n 159: 'old',\n 12: 'backyard',\n 198: 'sick',\n 136: 'look',\n 215: 'that',\n 24: 'black',\n 246: 'yourself',\n 161: 'open',\n 4: 'alligator',\n 146: 'moon',\n 78: 'find',\n 172: 'pizza',\n 194: 'shhh',\n 76: 'fast',\n 125: 'jacket',\n 192: 'scissors',\n 157: 'now',\n 140: 'man',\n 206: 'sticky',\n 127: 'jump',\n 199: 'sleep',\n 210: 'sun',\n 83: 'first',\n 101: 'grass',\n 228: 'uncle',\n 84: 'fish',\n 51: 'cowboy',\n 203: 'snow',\n 66: 'dryer',\n 102: 'green',\n 32: 'bug',\n 150: 'nap',\n 77: 'feet',\n 247: 'yucky',\n 147: 'morning',\n 189: 'sad',\n 73: 'face',\n 169: 'penny',\n 92: 'gift',\n 152: 'night',\n 104: 'hair',\n 239: 'who',\n 217: 'think',\n 31: 'brown',\n 138: 'mad',\n 17: 'bed',\n 63: 'drink',\n 205: 'stay',\n 85: 'flag',\n 223: 'tooth',\n 11: 'awake',\n 214: 'thankyou',\n 120: 'hot',\n 132: 'like',\n 237: 'where',\n 115: 'hesheit',\n 176: 'potty',\n 61: 'down',\n 209: 'stuck',\n 153: 'no',\n 110: 'head',\n 87: 'food',\n 178: 'pretty',\n 158: 'nuts',\n 5: 'animal',\n 90: 'frog',\n 21: 'beside',\n 154: 'noisy',\n 234: 'water',\n 236: 'weus',\n 105: 'happy',\n 238: 'white',\n 33: 'bye',\n 117: 'high',\n 79: 'fine',\n 27: 'boat',\n 3: 'all',\n 219: 'tiger',\n 168: 'pencil',\n 200: 'sleepy',\n 99: 'grandma',\n 44: 'chocolate',\n 109: 'haveto',\n 182: 'radio',\n 75: 'farm',\n 7: 'any',\n 248: 'zebra',\n 183: 'rain',\n 226: 'toy',\n 60: 'donkey',\n 133: 'lion',\n 64: 'drop',\n 141: 'many',\n 15: 'bath',\n 10: 'aunt',\n 241: 'will',\n 107: 'hate',\n 160: 'on',\n 177: 'pretend',\n 129: 'kitty',\n 82: 'fireman',\n 20: 'before',\n 59: 'doll',\n 204: 'stairs',\n 128: 'kiss',\n 137: 'loud',\n 114: 'hen',\n 135: 'listen',\n 95: 'give',\n 242: 'wolf',\n 55: 'dad',\n 103: 'gum',\n 111: 'hear',\n 186: 'refrigerator',\n 163: 'outside',\n 53: 'cut',\n 229: 'underwear',\n 173: 'please',\n 42: 'child',\n 201: 'smile',\n 167: 'pen',\n 245: 'yesterday',\n 119: 'horse',\n 171: 'pig',\n 211: 'table',\n 72: 'eye',\n 202: 'snack',\n 208: 'story',\n 174: 'police',\n 9: 'arm',\n 212: 'talk',\n 100: 'grandpa',\n 222: 'tongue',\n 175: 'pool',\n 94: 'girl',\n 230: 'up',\n 22: 'better',\n 227: 'tree',\n 56: 'dance',\n 46: 'close',\n 213: 'taste',\n 43: 'chin',\n 187: 'ride',\n 16: 'because',\n 123: 'if',\n 38: 'cat',\n 240: 'why',\n 37: 'carrot',\n 58: 'dog',\n 148: 'mouse',\n 126: 'jeans',\n 197: 'shower',\n 131: 'later',\n 145: 'mom',\n 155: 'nose',\n 244: 'yes',\n 2: 'airplane',\n 28: 'book',\n 26: 'blue',\n 122: 'icecream',\n 91: 'garbage',\n 221: 'tomorrow',\n 185: 'red',\n 50: 'cow',\n 170: 'person',\n 179: 'puppy',\n 39: 'cereal',\n 225: 'touch',\n 149: 'mouth',\n 29: 'boy',\n 218: 'thirsty',\n 139: 'make',\n 88: 'for',\n 96: 'glasswindow',\n 124: 'into',\n 184: 'read',\n 71: 'every',\n 18: 'bedroom',\n 151: 'napkin',\n 68: 'ear',\n 224: 'toothbrush',\n 118: 'home',\n 166: 'pajamas',\n 113: 'hello',\n 112: 'helicopter',\n 130: 'lamp',\n 188: 'room',\n 57: 'dirty',\n 40: 'chair',\n 106: 'hat',\n 69: 'elephant',\n 1: 'after',\n 36: 'car',\n 116: 'hide',\n 98: 'goose'}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load Relevant Data","metadata":{}},{"cell_type":"code","source":"def load_relevant_data_subset(pq_path):\n    #data_columns = ['x','y','z'] #IF USING Z VALUE BUT USUALY WE DONT\n    data_columns = ['x','y']\n    data = pd.read_parquet(pq_path, columns = data_columns)\n    n_frames = int(len(data) / TOTAL_LANDMARKS)\n    data = data.values.reshape(n_frames, TOTAL_LANDMARKS, len(data_columns))\n    return data.astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"class PreprocessLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super(PreprocessLayer, self).__init__()\n        normalisation_correction = tf.constant([\n                [0] * len(LIPS_INDICES) + [0.50] * len(LEFT_HAND_INDICES) + [0.50] * len(POSE_IDXS),\n                [0] * len(INDICES_LEFT_DOMINANT),\n                #[0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),#Uncomment when using Z Value\n            ],\n            dtype=tf.float32,\n        )\n        self.normalisation_correction = tf.transpose(normalisation_correction, [1, 0])\n\n    def padding_edge(self, t, repeats, side):\n        if side == 'LEFT':\n            return tf.concat([tf.repeat(t[:1], repeats=repeats, axis=0), t], axis=0)\n        elif side == 'RIGHT':\n            return tf.concat([t, tf.repeat(t[-1:], repeats=repeats, axis=0)], axis=0)\n\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, TOTAL_LANDMARKS, N_DIMS], dtype=tf.float32)])\n    def call(self, input_data):\n        N_FRAMES0 = tf.shape(input_data)[0]\n\n        left_hand_sum = tf.reduce_sum(tf.where(tf.math.is_nan(tf.gather(input_data, LEFT_HAND_INDICES, axis=1)), 0, 1))\n        right_hand_sum = tf.reduce_sum(tf.where(tf.math.is_nan(tf.gather(input_data, RIGHT_HAND_INDICES, axis=1)), 0, 1))\n        left_dominant = left_hand_sum >= right_hand_sum\n\n        if left_dominant:\n            dominant_hand_idxs = LEFT_HAND_INDICES\n        else:\n            dominant_hand_idxs = RIGHT_HAND_INDICES\n            \n        frames_hands_non_nan_sum = tf.math.reduce_sum(\n             tf.where(tf.math.is_nan(tf.gather(input_data, dominant_hand_idxs, axis=1)), 0, 1),\n             axis=[1, 2]\n         )    \n        \n        non_empty_frames_idxs = tf.where(frames_hands_non_nan_sum > 0)\n        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n        data = tf.gather(input_data, non_empty_frames_idxs, axis=0)\n\n        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32)\n        non_empty_frames_idxs -= tf.reduce_min(non_empty_frames_idxs)\n\n        N_FRAMES = tf.shape(data)[0]\n\n        if left_dominant:\n            data = tf.gather(data, INDICES_LEFT_DOMINANT, axis=1)\n        else:\n            data = tf.gather(data, INDICES_RIGHT_DOMINANT, axis=1)\n            data = self.normalisation_correction + (\n                (data - self.normalisation_correction) * tf.where(self.normalisation_correction != 0, -1.0, 1.0))\n\n        if N_FRAMES < INPUT_SIZE:\n            pad_size = INPUT_SIZE - N_FRAMES\n            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, pad_size]], constant_values=-1)\n            data = tf.pad(data, [[0, pad_size], [0, 0], [0, 0]], constant_values=0)\n            data = tf.where(tf.math.is_nan(data), 0.0, data)\n            return data, non_empty_frames_idxs\n        else:\n            if N_FRAMES < INPUT_SIZE ** 2:\n                repeats = tf.math.floordiv(INPUT_SIZE * INPUT_SIZE, N_FRAMES0)\n                data = tf.repeat(data, repeats=repeats, axis=0)\n                non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n\n            pool_size = tf.math.floordiv(len(data), INPUT_SIZE)\n            if tf.math.mod(len(data), INPUT_SIZE) > 0:\n                pool_size += 1\n\n            pad_size = (pool_size * INPUT_SIZE) - len(data) if pool_size == 1 else (pool_size * INPUT_SIZE) % len(data)\n            pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n            pad_right = pad_left + 1 if tf.math.mod(pad_size, 2) > 0 else pad_left\n\n            data = self.padding_edge(data, pad_left, 'LEFT')\n            data = self.padding_edge(data, pad_right, 'RIGHT')\n            non_empty_frames_idxs = self.padding_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n            non_empty_frames_idxs = self.padding_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n\n            data = tf.reshape(data, [INPUT_SIZE, -1, N_COLS, N_DIMS])\n            non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [INPUT_SIZE, -1])\n            \n            #\n            data = tf.reduce_mean(data, axis=1)\n            non_empty_frames_idxs = tf.reduce_mean(non_empty_frames_idxs, axis=1)\n\n            data = tf.where(tf.math.is_nan(data), 0.0, data)\n            \n            return data, non_empty_frames_idxs\n\npreprocess_layer = PreprocessLayer()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_preprocess(file_path):\n    data = load_relevant_data_subset(file_path)\n    data = preprocess_layer(data)    \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_arrays(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS):\n    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n    y = np.zeros([N_SAMPLES], dtype=np.int32)\n    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n    return X, y, NON_EMPTY_FRAME_IDXS\n\ndef save_split_data(X, y, NON_EMPTY_FRAME_IDXS, train_idxs, val_idxs):\n    X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN = X[train_idxs], y[train_idxs], NON_EMPTY_FRAME_IDXS[train_idxs]\n    X_val, y_val, NON_EMPTY_FRAME_IDXS_VAL = X[val_idxs], y[val_idxs], NON_EMPTY_FRAME_IDXS[val_idxs]\n    \n    np.save('X_train.npy', X_train)\n    np.save('y_train.npy', y_train)\n    np.save('NON_EMPTY_FRAME_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n    \n    np.save('X_val.npy', X_val)\n    np.save('y_val.npy', y_val)\n    np.save('NON_EMPTY_FRAME_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n    \n    return X_train, y_train, X_val, y_val\n\ndef log_split_statistics(PARTICIPANT_IDS, train_idxs, val_idxs, X_train, y_train, X_val, y_val):\n    print(f'Patient Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')\n\ndef preprocess_data(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS, train, SEED):\n    X, y, NON_EMPTY_FRAME_IDXS = initialize_arrays(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS)\n    \n    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'ord_value']].values)):\n        if row_idx % 5000 == 0:\n            print(f'Generated {row_idx}/{N_SAMPLES}')\n        \n        data, non_empty_frame_idxs = get_data_preprocess(file_path)\n        X[row_idx] = data\n        y[row_idx] = sign_ord\n        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n        \n        if np.isnan(data).sum() > 0:\n            print(f'NaN values found at row {row_idx}')\n            return data\n    \n    splitter = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=SEED)\n    PARTICIPANT_IDS = train['participant_id'].values\n    train_idxs, val_idxs = next(splitter.split(X, y, groups=PARTICIPANT_IDS))\n    \n    X_train, y_train, X_val, y_val = save_split_data(X, y, NON_EMPTY_FRAME_IDXS, train_idxs, val_idxs)\n    \n    log_split_statistics(PARTICIPANT_IDS, train_idxs, val_idxs, X_train, y_train, X_val, y_val)\n\npreprocess_data(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS, train, SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from sklearn.model_selection import GroupShuffleSplit\n# from tqdm import tqdm\n\n# def initialize_arrays(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS):\n#     X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n#     y = np.zeros([N_SAMPLES], dtype=np.int32)\n#     NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n#     return X, y, NON_EMPTY_FRAME_IDXS\n\n# def save_split_data(X, y, NON_EMPTY_FRAME_IDXS, train_idxs, val_idxs, test_idxs):\n#     X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN = X[train_idxs], y[train_idxs], NON_EMPTY_FRAME_IDXS[train_idxs]\n#     X_val, y_val, NON_EMPTY_FRAME_IDXS_VAL = X[val_idxs], y[val_idxs], NON_EMPTY_FRAME_IDXS[val_idxs]\n# #     X_test, y_test, NON_EMPTY_FRAME_IDXS_TEST = X[test_idxs], y[test_idxs], NON_EMPTY_FRAME_IDXS[test_idxs]\n    \n#     np.save('X_train.npy', X_train)\n#     np.save('y_train.npy', y_train)\n#     np.save('NON_EMPTY_FRAME_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n    \n#     np.save('X_val.npy', X_val)\n#     np.save('y_val.npy', y_val)\n#     np.save('NON_EMPTY_FRAME_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n    \n# #     np.save('X_test.npy', X_test)\n# #     np.save('y_test.npy', y_test)\n# #     np.save('NON_EMPTY_FRAME_TEST.npy', NON_EMPTY_FRAME_IDXS_TEST)\n    \n#     return X_train, y_train, X_val, y_val, X_test, y_test\n\n# # def log_split_statistics(PARTICIPANT_IDS, train_idxs, val_idxs, test_idxs, X_train, y_train, X_val, y_val, X_test, y_test):\n# #     print(f'Patient Train/Val/Test: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs]).intersection(PARTICIPANT_IDS[test_idxs])}')\n# #     print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}, X_test shape: {X_test.shape}')\n# #     print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}, y_test shape: {y_test.shape}')\n\n# def preprocess_data(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS, train, SEED):\n#     X, y, NON_EMPTY_FRAME_IDXS = initialize_arrays(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS)\n    \n#     for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'ord_value']].values)):\n#         if row_idx % 5000 == 0:\n#             print(f'Generated {row_idx}/{N_SAMPLES}')\n        \n#         data, non_empty_frame_idxs = get_data_preprocess(file_path)\n#         X[row_idx] = data\n#         y[row_idx] = sign_ord\n#         NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n        \n#         if np.isnan(data).sum() > 0:\n#             print(f'NaN values found at row {row_idx}')\n#             return data\n    \n#     splitter = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=SEED)\n#     PARTICIPANT_IDS = train['participant_id'].values\n#     train_val_idxs, test_idxs = next(splitter.split(X, y, groups=PARTICIPANT_IDS))\n    \n#     splitter_val = GroupShuffleSplit(test_size=0.25, n_splits=2, random_state=SEED)\n#     train_idxs, val_idxs = next(splitter_val.split(X[train_val_idxs], y[train_val_idxs], groups=PARTICIPANT_IDS[train_val_idxs]))\n#     train_idxs = train_val_idxs[train_idxs]\n#     val_idxs = train_val_idxs[val_idxs]\n    \n#     X_train, y_train, X_val, y_val, X_test, y_test = save_split_data(X, y, NON_EMPTY_FRAME_IDXS, train_idxs, val_idxs, test_idxs)\n    \n#     log_split_statistics(PARTICIPANT_IDS, train_idxs, val_idxs, test_idxs, X_train, y_train, X_val, y_val, X_test, y_test)\n\n# preprocess_data(N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS, train, SEED)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load New Data from NPY file","metadata":{}},{"cell_type":"code","source":"def display_shapes_and_dtypes(data, names):\n    for element, name in zip(data, names):\n        print(f'{name} shape: {element.shape}, dtype: {element.dtype}')","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:39:40.857802Z","iopub.execute_input":"2024-06-02T09:39:40.858514Z","iopub.status.idle":"2024-06-02T09:39:40.863157Z","shell.execute_reply.started":"2024-06-02T09:39:40.858477Z","shell.execute_reply":"2024-06-02T09:39:40.862282Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# # ROOT_DIR = '/kaggle/input/gisl-npy/gisl-preproc'\n# ROOT_DIR = ''\n# X_train = np.load(f'{ROOT_DIR}/X_train.npy')\n# y_train = np.load(f'{ROOT_DIR}/y_train.npy')\n# NON_EMPTY_FRAME_TRAIN = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_TRAIN.npy')\n\n# X_val = np.load(f'{ROOT_DIR}/X_val.npy')\n# y_val = np.load(f'{ROOT_DIR}/y_val.npy')\n# NON_EMPTY_FRAME_VAL = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_VAL.npy')\n# validation_data = ({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_VAL }, y_val)\n\n# # X_test = np.load(f'{ROOT_DIR}/X_test.npy')\n# # y_test = np.load(f'{ROOT_DIR}/y_test.npy')\n# # NON_EMPTY_FRAME_TEST = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_TEST.npy')\n# # validation_data = ({ 'frames': X_test, 'non_empty_frame_idxs': NON_EMPTY_FRAME_TEST }, y_test)\n\n\n# display_shapes_and_dtypes([X_train, y_train, NON_EMPTY_FRAME_TRAIN], ['X_train', 'y_train', 'NON_EMPTY_FRAME_TRAIN'])\n# display_shapes_and_dtypes([X_val, y_val, NON_EMPTY_FRAME_VAL], ['X_val', 'y_val', 'NON_EMPTY_FRAME_VAL'])\n# # display_shapes_and_dtypes([X_test, y_test, NON_EMPTY_FRAME_TEST], ['X_test', 'y_test', 'NON_EMPTY_FRAME_TEST'])\n\n# print(f'# NaN Values X_train: {np.isnan(X_train).sum()}')\n# print(f'# NaN Values X_val: {np.isnan(X_val).sum()}')\n# # print(f'# NaN Values X_test: {np.isnan(X_test).sum()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/gislr-dataset-public'\nX_train = np.load(f'{ROOT_DIR}/X_train.npy')\nX_train = X_train[:, :, :, :2]\ny_train = np.load(f'{ROOT_DIR}/y_train.npy')\nNON_EMPTY_FRAME_TRAIN = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS_TRAIN.npy')\nX_val = np.load(f'{ROOT_DIR}/X_val.npy')\nX_val = X_val[:, :, :, :2]\ny_val = np.load(f'{ROOT_DIR}/y_val.npy')\nNON_EMPTY_FRAME_VAL = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS_VAL.npy')\nvalidation_data = ({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_VAL }, y_val)\ndisplay_shapes_and_dtypes([X_train, y_train, NON_EMPTY_FRAME_TRAIN], ['X_train', 'y_train', 'NON_EMPTY_FRAME_IDXS_TRAIN'])\ndisplay_shapes_and_dtypes([X_val, y_val, NON_EMPTY_FRAME_VAL], ['X_val', 'y_val', 'NON_EMPTY_FRAME_IDXS_VAL'])\nprint(f'# NaN Values X_train: {np.isnan(X_train).sum()}')","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:39:42.836289Z","iopub.execute_input":"2024-06-02T09:39:42.836635Z","iopub.status.idle":"2024-06-02T09:39:47.896548Z","shell.execute_reply.started":"2024-06-02T09:39:42.836608Z","shell.execute_reply":"2024-06-02T09:39:47.895547Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"X_train shape: (80229, 64, 66, 2), dtype: float32\ny_train shape: (80229,), dtype: int32\nNON_EMPTY_FRAME_IDXS_TRAIN shape: (80229, 64), dtype: float32\nX_val shape: (14248, 64, 66, 2), dtype: float32\ny_val shape: (14248,), dtype: int32\nNON_EMPTY_FRAME_IDXS_VAL shape: (14248, 64), dtype: float32\n# NaN Values X_train: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Normalisation","metadata":{}},{"cell_type":"code","source":"def get_lips_mean_std():\n    # LIPS\n    LIPS_MEAN_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n    LIPS_MEAN_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n    LIPS_STD_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n    LIPS_STD_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n\n    for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, N_DIMS, -1]) )):\n        for dim, l in enumerate(ll):\n            v = l[np.nonzero(l)]\n            if dim == 0: # X\n                LIPS_MEAN_X[col] = v.mean()\n                LIPS_STD_X[col] = v.std()\n            if dim == 1: # Y\n                LIPS_MEAN_Y[col] = v.mean()\n                LIPS_STD_Y[col] = v.std()\n    \n    \n    LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n    LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T\n    \n    return LIPS_MEAN, LIPS_STD\n\nLIPS_MEAN, LIPS_STD = get_lips_mean_std()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:39:47.898339Z","iopub.execute_input":"2024-06-02T09:39:47.898731Z","iopub.status.idle":"2024-06-02T09:39:56.179037Z","shell.execute_reply.started":"2024-06-02T09:39:47.898696Z","shell.execute_reply":"2024-06-02T09:39:56.178103Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45af0f14f7294e80a1d10d777a563144"}},"metadata":{}}]},{"cell_type":"code","source":"def get_left_right_hand_mean_std():\n    # LEFT HAND\n    LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n    LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n    LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n    LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n\n    for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,LEFT_HAND_IDXS], [2,3,0,1]).reshape([LEFT_HAND_IDXS.size, N_DIMS, -1]) )):\n        for dim, l in enumerate(ll):\n            v = l[np.nonzero(l)]\n            if dim == 0: # X\n                LEFT_HANDS_MEAN_X[col] = v.mean()\n                LEFT_HANDS_STD_X[col] = v.std()\n            if dim == 1: # Y\n                LEFT_HANDS_MEAN_Y[col] = v.mean()\n                LEFT_HANDS_STD_Y[col] = v.std()\n\n    LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n    LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n    \n    return LEFT_HANDS_MEAN, LEFT_HANDS_STD\n\nLEFT_HANDS_MEAN, LEFT_HANDS_STD = get_left_right_hand_mean_std()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:39:56.180535Z","iopub.execute_input":"2024-06-02T09:39:56.180920Z","iopub.status.idle":"2024-06-02T09:40:00.477466Z","shell.execute_reply.started":"2024-06-02T09:39:56.180886Z","shell.execute_reply":"2024-06-02T09:40:00.476538Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/21 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb9ab8103df84938a9b63a2d657104ef"}},"metadata":{}}]},{"cell_type":"code","source":"def get_pose_mean_std():\n    # POSE\n    POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n    POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n    POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n    POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n\n    for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, N_DIMS, -1]) )):\n        for dim, l in enumerate(ll):\n            v = l[np.nonzero(l)]\n            if dim == 0: # X\n                POSE_MEAN_X[col] = v.mean()\n                POSE_STD_X[col] = v.std()\n            if dim == 1: # Y\n                POSE_MEAN_Y[col] = v.mean()\n                POSE_STD_Y[col] = v.std()\n\n    POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n    POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T\n    \n    return POSE_MEAN, POSE_STD\n\nPOSE_MEAN, POSE_STD = get_pose_mean_std()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:40:00.480057Z","iopub.execute_input":"2024-06-02T09:40:00.480351Z","iopub.status.idle":"2024-06-02T09:40:01.536291Z","shell.execute_reply.started":"2024-06-02T09:40:00.480324Z","shell.execute_reply":"2024-06-02T09:40:01.535292Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a09d96c0b946fe86605e1651d7a6bb"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Samples","metadata":{}},{"cell_type":"code","source":"BATCH_ALL_SIGNS_N = 4","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:40:01.537379Z","iopub.execute_input":"2024-06-02T09:40:01.537648Z","iopub.status.idle":"2024-06-02T09:40:01.541707Z","shell.execute_reply.started":"2024-06-02T09:40:01.537625Z","shell.execute_reply":"2024-06-02T09:40:01.540819Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Custom sampler to get a batch containing N times all signs\ndef get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n=BATCH_ALL_SIGNS_N):\n    # Arrays to store batch in\n    X_batch = np.zeros([NUM_CLASS*n, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n    y_batch = np.arange(0, NUM_CLASS, step=1/n, dtype=np.float32).astype(np.int64)\n    non_empty_frame_idxs_batch = np.zeros([NUM_CLASS*n, INPUT_SIZE], dtype=np.float32)\n    \n    # Dictionary mapping ordinally encoded sign to corresponding sample indices\n    CLASS2IDXS = {}\n    for i in range(NUM_CLASS):\n        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n            \n    while True:\n        # Fill batch arrays\n        for i in range(NUM_CLASS):\n            idxs = np.random.choice(CLASS2IDXS[i], n)\n            X_batch[i*n:(i+1)*n] = X[idxs]\n            non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n        \n        yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:40:01.542936Z","iopub.execute_input":"2024-06-02T09:40:01.543257Z","iopub.status.idle":"2024-06-02T09:40:01.552859Z","shell.execute_reply.started":"2024-06-02T09:40:01.543227Z","shell.execute_reply":"2024-06-02T09:40:01.551942Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Transformer Model","metadata":{}},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:47.030426Z","iopub.execute_input":"2024-06-02T09:46:47.031173Z","iopub.status.idle":"2024-06-02T09:46:47.037033Z","shell.execute_reply.started":"2024-06-02T09:46:47.031137Z","shell.execute_reply":"2024-06-02T09:46:47.036109Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:47.457729Z","iopub.execute_input":"2024-06-02T09:46:47.458115Z","iopub.status.idle":"2024-06-02T09:46:47.651143Z","shell.execute_reply.started":"2024-06-02T09:46:47.458085Z","shell.execute_reply":"2024-06-02T09:46:47.650141Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"2638"},"metadata":{}}]},{"cell_type":"code","source":"do = 0.3\n\nmodel = tf.keras.Sequential()\nmodel.add(InputLayer(input_shape=(64, 66, 2)))\nmodel.add(Reshape((64, 66*2)))\n\nmodel.add(Conv1D(64, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(Conv1D(64, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv1D(3, strides=1, padding='valid', depth_multiplier=1, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv1D(128, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(Conv1D(128, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv1D(3, strides=1, padding='valid', depth_multiplier=1, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv1D(180, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(Conv1D(180, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv1D(5, strides=2, padding='valid', depth_multiplier=4, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool1D(2, 2))\nmodel.add(LSTM(64, return_sequences=True))\n\nmodel.add(Conv1D(256, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(Conv1D(256, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv1D(3, strides=1, padding='valid', depth_multiplier=1, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv1D(512, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(Conv1D(512, 1, strides=1, padding='valid', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv1D(5, strides=2, padding='valid', depth_multiplier=4, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(GlobalAvgPool1D())\nmodel.add(Dropout(rate=do))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate=do))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate=do))\n\nmodel.add(Dense(250, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:48.260542Z","iopub.execute_input":"2024-06-02T09:46:48.260930Z","iopub.status.idle":"2024-06-02T09:46:49.644426Z","shell.execute_reply.started":"2024-06-02T09:46:48.260892Z","shell.execute_reply":"2024-06-02T09:46:49.643451Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler\nimport math","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:50.455761Z","iopub.execute_input":"2024-06-02T09:46:50.456122Z","iopub.status.idle":"2024-06-02T09:46:50.461232Z","shell.execute_reply.started":"2024-06-02T09:46:50.456093Z","shell.execute_reply":"2024-06-02T09:46:50.460334Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def step_decay(epoch):\n    initial_lr = 0.001\n    drop = 0.5\n    epochs_drop = 10\n    lr = initial_lr * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n    return lr\n\n# Create the LearningRateScheduler callback\nlr_scheduler = LearningRateScheduler(step_decay)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:51.410556Z","iopub.execute_input":"2024-06-02T09:46:51.411224Z","iopub.status.idle":"2024-06-02T09:46:51.416376Z","shell.execute_reply.started":"2024-06-02T09:46:51.411187Z","shell.execute_reply":"2024-06-02T09:46:51.415393Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics = ['acc']\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:51.886588Z","iopub.execute_input":"2024-06-02T09:46:51.886918Z","iopub.status.idle":"2024-06-02T09:46:51.902041Z","shell.execute_reply.started":"2024-06-02T09:46:51.886890Z","shell.execute_reply":"2024-06-02T09:46:51.901066Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    min_delta=0.001,\n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:52.450917Z","iopub.execute_input":"2024-06-02T09:46:52.451266Z","iopub.status.idle":"2024-06-02T09:46:52.455994Z","shell.execute_reply.started":"2024-06-02T09:46:52.451239Z","shell.execute_reply":"2024-06-02T09:46:52.454928Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=N_EPOCHS,\n    batch_size=64,\n    validation_data=(X_val, y_val),\n    verbose = 2,\n    callbacks = [lr_scheduler, early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T09:46:53.125841Z","iopub.execute_input":"2024-06-02T09:46:53.126168Z","iopub.status.idle":"2024-06-02T09:54:49.247005Z","shell.execute_reply.started":"2024-06-02T09:46:53.126142Z","shell.execute_reply":"2024-06-02T09:54:49.245661Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n1254/1254 - 51s - 40ms/step - acc: 0.0230 - loss: 5.1875 - val_acc: 0.0503 - val_loss: 4.4963 - learning_rate: 0.0010\nEpoch 2/1000\n1254/1254 - 33s - 26ms/step - acc: 0.0915 - loss: 4.2124 - val_acc: 0.0313 - val_loss: 5.4787 - learning_rate: 0.0010\nEpoch 3/1000\n1254/1254 - 33s - 26ms/step - acc: 0.1865 - loss: 3.5563 - val_acc: 0.0425 - val_loss: 5.5325 - learning_rate: 0.0010\nEpoch 4/1000\n1254/1254 - 33s - 26ms/step - acc: 0.2587 - loss: 3.1474 - val_acc: 0.2019 - val_loss: 3.4164 - learning_rate: 0.0010\nEpoch 5/1000\n1254/1254 - 33s - 26ms/step - acc: 0.3183 - loss: 2.8537 - val_acc: 0.0943 - val_loss: 5.4512 - learning_rate: 0.0010\nEpoch 6/1000\n1254/1254 - 33s - 26ms/step - acc: 0.3642 - loss: 2.6393 - val_acc: 0.1289 - val_loss: 4.2982 - learning_rate: 0.0010\nEpoch 7/1000\n1254/1254 - 33s - 26ms/step - acc: 0.3966 - loss: 2.4831 - val_acc: 0.1347 - val_loss: 4.3763 - learning_rate: 0.0010\nEpoch 8/1000\n1254/1254 - 33s - 26ms/step - acc: 0.4239 - loss: 2.3591 - val_acc: 0.1874 - val_loss: 3.8381 - learning_rate: 0.0010\nEpoch 9/1000\n1254/1254 - 33s - 26ms/step - acc: 0.4497 - loss: 2.2510 - val_acc: 0.1748 - val_loss: 4.0068 - learning_rate: 0.0010\nEpoch 10/1000\n1254/1254 - 33s - 26ms/step - acc: 0.5017 - loss: 2.0161 - val_acc: 0.5012 - val_loss: 1.9546 - learning_rate: 5.0000e-04\nEpoch 11/1000\n1254/1254 - 33s - 26ms/step - acc: 0.5215 - loss: 1.9309 - val_acc: 0.3968 - val_loss: 2.5757 - learning_rate: 5.0000e-04\nEpoch 12/1000\n1254/1254 - 41s - 33ms/step - acc: 0.5324 - loss: 1.8793 - val_acc: 0.4902 - val_loss: 2.0406 - learning_rate: 5.0000e-04\nEpoch 13/1000\n1254/1254 - 33s - 26ms/step - acc: 0.5443 - loss: 1.8266 - val_acc: 0.3163 - val_loss: 3.0357 - learning_rate: 5.0000e-04\nEpoch 14/1000\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}